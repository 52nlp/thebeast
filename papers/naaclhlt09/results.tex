
The results of our system using the dependency-based evaluation from CoNLL-08
are shown in Table \ref{tbl:results}. Our results, are comparable with state of
the art results for the task. Our best model would be ranked 4th in the open
track with system which used better quality of depenencies trees. 

\begin{table}[ht]
    \centering
    \begin{tabular}{|p{2.5cm}|c|c|c|}\hline
        System                    & Devel      & WSJ       & Brown \\\hline 
        Full model                & $76.93\%$  & $79.09\%$ & $67.64\%$ \\
        Bottom-up                 & $77.96\%$  & $80.26\%$ & $67.75\%$ \\
        Full model w/o isArgument &            &           &           \\
        Bottom-up  w/o isArgument & $77.57\%$  & $79.37\%$ & $66.70\%$ \\
        Pipeline                  & $75.69\%$  & $78.19\%$ & $64.66\%$ \\\hline
    \end{tabular}
    \caption{Labelled $F_1$ scores of our five systems using CoNLL-08
    evaluation.}
    \label{tbl:results}
\end{table}

The table \ref{tbl:results} shows that our best system is the bottom-up model. When compared with
the pipeline system, there is a significant difference in the WSJ test set. However, this difference
is more notable for the Brown test set. Table \ref{tbl:predicates} shows the
evaluation per predicate in the pipeline and the bottom-up systems. We notice
that the better performance comes from the sense predicate. A similar pattern is
observed with the WSJ.

% explain why ??

\begin{table}[ht]

    \centering
    \begin{tabular}{|c|c|c|}\hline
                                  & Pipeline  &  Bottom-up \\\hline 
        \emph{isPredicate}        & $92.2\%$  & $92.5\%$  \\
        \emph{isArgument}         & $85.9\%$  & $86.6\%$  \\
        \emph{hasRole}            & $83.6\%$  & $83.6\%$  \\
        \emph{role}               & $64.2\%$  & $66.2\%$  \\
        \emph{sense}              & $67.3\%$  & $77.5\%$  \\\hline
    \end{tabular}
    \caption{$F_1$ scores for ML predicates in Brown corpus.}
    \label{tbl:predicates}
\end{table}

% I don't quite understand why we did isArg vs no isArg :-S. Maybe, too late to
% bring the issue. I just put two columns, if I put dev and brown, they get too
% big.

\begin{table}[ht]

    \centering
    \begin{tabular}{|c|c|c|}\hline
                                  & Bottom-up  &  Bottom-up \\
                                  &            &  w/o \emph{isArgument} \\\hline 
        \emph{isPredicate}        & $96.5\%$   & $96.3\%$   \\
        \emph{isArgument}         & $90.4\%$   &   N/A      \\
        \emph{hasRole}            & $87.7\%$   & $87.1\%$   \\
        \emph{role}               & $77.5\%$   & $76.9\%$   \\
        \emph{sense}              & $89.0\%$   & $88.3\%$   \\
        \hline
    \end{tabular}
    \caption{$F_1$ scores for ML predicates for WSJ.}
    \label{tbl:predicates}
\end{table}


When modeling a joint model a concern is the efficiency of the approach. Table
\ref{tbl:times} shows the times for training and testing. We notice that the
joint models are competitive when compared with the pipeline approach. However,
we can notice the efect of reducing the complexity of the model, as happens with
the bottom-up and the models without the \emph{isArgument} predicate which are
faster to train. Table \ref{tbl:nocpi} shows the times for testing when the CPI
algorithm is off. As we can see the CPI algorithm helps to keep the ML approach
efficient for the SRL task.

\begin{table}[ht]

    \centering
    \begin{tabular}{|p{2.5cm}|c|c|c|}\hline
        System                           & Training & Testing   & Testing \\
                                         &          & WSJ       & Brown   \\\hline 
        Full model                       & $5.1$h   & $9.2$m    & $1.5$m  \\
        Bottom-up                        & $4.3$ih  & $9.5$m    & $1.6$m  \\
        Full model w/o \emph{isArgument} &          &           &         \\
        Bottom-up  w/o \emph{isArgument} & $3.9$h   & $12.5$m   & $1.5$m \\
        Pipeline                         & $5.0$h   & $18.9$m   & $2.9$m \\\hline
    \end{tabular}
    \caption{Testing and training times for the systems.}
    \label{tbl:times}
\end{table}

\begin{table}[ht]

    \centering
    \begin{tabular}{|p{2.5cm}|c|c|}\hline
        System                           & Testing   & Testing \\
                                         & WSJ       & Brown   \\\hline 
        Full model                       & $38.4$m   & $7.47$m  \\
        Bottom-up                        & $38.8$m   & $6.9$m  \\
    \end{tabular}
    \caption{Testing times for full model and bottom-up when CPI algorithm is
    not used.}
    \label{tbl:nocpi}
\end{table}


%7. Results
%7.1 Joint/Bottom-up vs pipeline
%- Illustrate that we get dramatic improvements in sense
%disambiguation, but not in other parts. Stress effect on Brown
%- Show table that compares isPredicate & role & frameLabel results for
%pipeline vs joint models (this would show that no gain in isPredicate
%and role, but in frameLabel)
%- Give example from dev-set
%7.2 With isArg vs without isArg
%- illustrate that we get improvements in all sections
%- show table that compares individual predicate scores (dev, wsj,
%brown) for isArg vs w/o isArg
%- maybe find example?
%7.3 (Maybe) Full vs Bottom-up again (maybe not because in other paper)
%7.4 Efficiency
%- Illustrate that training the model jointly comes at no extra cost
%(we can train as fast/faster with the joint bottom up model than with
%a pipeline)
%- Illustrate that inference is much more efficient when compared to an
%equivalent ILP-only system (which is basically the w/o CPI system)
%- Can we also have a sentence/second column for testing?
%
%
%Pipeline
%**************
%         isPredicate    : 0.958,0.959,0.958,0.959,0.959
%          isArgument    : 0.890,0.892,0.891,0.891,0.891
%            hasLabel    : 0.870,0.873,0.872,0.872,0.872
%                role    : 0.706,0.718,0.720,0.722,0.723
%          frameLabel    : 0.834,0.842,0.841,0.841,0.841
%
%         isPredicate    : 0.966,0.922
%          isArgument    : 0.903,0.859
%            hasLabel    : 0.880,0.836
%                role    : 0.754,0.642
%          frameLabel    : 0.855,0.673
%
%Times :
%trainning (hrs):
%stage1= 0.76
%stage2= 3.42
%stage3= 0.84
%total = 5.02
%testing:
%stage1: 5.44m, 42.68s
%stage2: 7.56m, 1.27m 
%stage3: 5.96m, 54.03s
%total: 18.96,  2.90m
%
%
%WSJ
%  Labeled precision:          (10284 + 4521) / (13021 + 5321) * 100 = 80.72 %
%  Labeled recall:             (10284 + 4521) / (14269 + 5260) * 100 = 75.81 %
%  Labeled F1:                 78.19
%
%Brown
%  Labeled precision:          (1335 + 555) / (1986 + 846) * 100 = 66.74 %
%  Labeled recall:             (1335 + 555) / (2210 + 804) * 100 = 62.71 %
%  Labeled F1:                 64.66
%
%
%
%Full model
%**************
%         isPredicate    : 0.958,0.959,0.958,0.958,0.958
%          isArgument    : 0.894,0.895,0.895,0.895,0.895
%            hasLabel    : 0.865,0.868,0.869,0.869,0.869
%                role    : 0.703,0.713,0.720,0.724,0.727
%          frameLabel    : 0.870,0.874,0.878,0.877,0.878
%
%         isPredicate    : 0.965,0.923
%          isArgument    : 0.906,0.869
%            hasLabel    : 0.879,0.838
%                role    : 0.755,0.646
%          frameLabel    : 0.885,0.771
%
%Times:
%Training :5.09 hrs
%Testing:
%WSJ          9.15m 
%Brown        1.58m 
%
%
%WSJ
%  Labeled precision:          (10423 + 4664) / (13348 + 5273) * 100 = 81.02 %
%  Labeled recall:             (10423 + 4664) / (14269 + 5260) * 100 = 77.25 %
%  Labeled F1:                 79.09
%
%Brown
%  Labeled precision:          (1369 + 621) / (2063 + 807) * 100 = 69.34 %
%  Labeled recall:             (1369 + 621) / (2210 + 804) * 100 = 66.03 %
%  Labeled F1:                 67.64
%
%
%Full model w/o isArg (NOTE: not with new formula2/ we need it with bottom-up model as well)
%**************
%
%       isPredicate      : 0.955,0.955,0.954,0.955,0.955
%            hasLabel    : 0.860,0.863,0.866,0.865,0.865
%                role    : 0.710,0.722,0.727,0.730,0.730
%          frameLabel    : 0.869,0.874,0.875,0.876,0.875
%
%         isPredicate    : 0.963,0.910
%            hasLabel    : 0.872,0.818
%                role    : 0.752,0.638
%          frameLabel    : 0.878,0.761
%
%Times (hrs)
%Training: 4.58
%Testing:
%WSJ       9.53m 
%Brown     1.43m 
%
%
%
%WSJ
%  Labeled precision:          (10308 + 4615) / (13132 + 5257) * 100 = 81.15 %
%  Labeled recall:             (10308 + 4615) / (14269 + 5260) * 100 = 76.41 %
%  Labeled F1:                 78.71
%
%Brown
%  Labeled precision:          (1324 + 609) / (1973 + 797) * 100 = 69.78 %
%  Labeled recall:             (1324 + 609) / (2210 + 804) * 100 = 64.13 %
%  Labeled F1:                 66.84
%
%
%
%Bottom up
%**************
%         isPredicate    : 0.958,0.960,0.960,0.960,0.959
%          isArgument    : 0.893,0.895,0.895,0.894,0.894
%            hasLabel    : 0.867,0.870,0.869,0.870,0.869
%                role    : 0.728,0.738,0.743,0.746,0.747
%          frameLabel    : 0.872,0.878,0.885,0.887,0.883
%
%         isPredicate    : 0.965,0.925
%          isArgument    : 0.904,0.866
%            hasLabel    : 0.877,0.836
%                role    : 0.775,0.662
%          frameLabel    : 0.890,0.775
%
%Times:
%Training 4.26 hrs
%Testing:
%WSJ          9.53m 
%Brown        1.55m 
%
%WSJ
%  Labeled precision:          (10315 + 4590) / (12349 + 5262) * 100 = 84.63 %
%  Labeled recall:             (10315 + 4590) / (14269 + 5260) * 100 = 76.32 %
%  Labeled F1:                 80.26
%
%Brown
%  Labeled precision:          (1327 + 591) / (1836 + 812) * 100 = 72.43 %
%  Labeled recall:             (1327 + 591) / (2210 + 804) * 100 = 63.64 %
%  Labeled F1:                 67.75
%
%
%NO CPI 
%**************
%         isPredicate    : 0.959,0.958,0.958,0.957,0.957
%          isArgument    : 0.894,0.896,0.895,0.895,0.893
%            hasLabel    : 0.867,0.869,0.870,0.868,0.867
%                role    : 0.708,0.720,0.726,0.727,0.727
%          frameLabel    : 0.873,0.878,0.880,0.879,0.879
%
%         isPredicate    : 0.964,0.925
%          isArgument    : 0.905,0.865
%            hasLabel    : 0.877,0.836
%                role    : 0.775,0.661
%          frameLabel    : 0.886,0.778
%
%Times:
%training: 6.51 hrs
%testing:
% WSJ        38.06m
% Brown       6.73m 
%
%WSJ     
%  Labeled precision:          (10323 + 4546) / (12384 + 5267) * 100 = 84.24 %
%  Labeled recall:             (10323 + 4546) / (14269 + 5260) * 100 = 76.14 %
%  Labeled F1:                 79.98
%
%Brown
%  Labeled precision:          (1324 + 600) / (1833 + 812) * 100 = 72.74 %
%  Labeled recall:             (1324 + 600) / (2210 + 804) * 100 = 63.84 %
%  Labeled F1:                 68.00
%
%
%Without linguistic
%**************
%
%
%
%
%bottom-up w/o isArg
%**************
%         isPredicate    : 0.953,0.955,0.955,0.955,0.954
%            hasLabel    : 0.859,0.863,0.863,0.863,0.862
%                role    : 0.725,0.739,0.742,0.743,0.745
%          frameLabel    : 0.870,0.875,0.877,0.876,0.876
%
%         isPredicate    : 0.963,0.914
%            hasLabel    : 0.871,0.825
%                role    : 0.769,0.652
%          frameLabel    : 0.883,0.761
%
%Times
%Training: 3.84 hrs
%Testing:
%WSJ         12.52m
%Brown        1.50m 
%
%WSJ
%  SEMANTIC SCORES:
%  Labeled precision:          (10218 + 4495) / (12293 + 5252) * 100 = 83.86 %
%  Labeled recall:             (10218 + 4495) / (14269 + 5260) * 100 = 75.34 %
%  Labeled F1:                 79.37
%
%
%Brown
%  Labeled precision:          (1298 + 578) / (1806 + 805) * 100 = 71.85 %
%  Labeled recall:             (1298 + 578) / (2210 + 804) * 100 = 62.24 %
%  Labeled F1:                 66.70
%
%
