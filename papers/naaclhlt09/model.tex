

We define five hidden predicates for the three stages of the task. Figure \ref{fig:achitecture} illustrates these predicates and the stage they belong to. 
For predicate identification, we use the predicate \emph{isPredicate}. \emph{isPredicate(p)} indicates that the word in the position $p$ is an SRL predicate.
For argument identification and classification, we use the predicates \emph{isArgument}, \emph{hasRole} and \emph{role}. The atom \emph{isArgument(a)} signals that the word in the position $a$ is a SRL argument of some (unspecified) SRL predicate while \emph{hasRole(p,a)} indicates that the token at position $a$ is an argument of the predicate in position $p$. The predicate \emph{role(p,a,r)} corresponds to the decision that the argument in the position $a$ has the role $r$ with respect to the predicate in the position $p$. Finally, for sense disambiguation we  define the predicate \emph{sense(p,e)} which signals that predicate in position $p$ has the sense $e$. 

\begin{figure}
\begin{center}
    \includegraphics[scale=.70]{TaskArchitecture}
\end{center}
\caption{MLN hidden predicates divided in stages}
\label{fig:achitecture}
\end{figure}

Additionaly to the hidden predicates, we define observable predicates to
represent the information available in the corpus. These predicates are:
\begin{description}
    \item[\emph{word}] Orthography of the token.
    \item[\emph{lemma}] Predicted lemma for the form of the token.
    \item[\emph{ppos}] Predicted POS tag for the form of the token.
    \item[\emph{cpos}] Predicted coarse POS tag for the form of the token.
    \item[\emph{possiblePredicate}] True if the token can be a predicate based on inspecting its POS tag.
    \item[\emph{possibleArgument}] True if the form can be a argument based on inspecting its POS tag.
    \item[\emph{voice}] Voice of the form if it is a verb (Active/Passive).
    \item[\emph{dep}] Syntactic dependency relation.
    \item[\emph{head}] Syntactic head of the current token.
    \item[\emph{palmer}] True if prunned by heuristics proposed in
        \citet{.}.
%  mst_frame_unlabeled 
%  mst_path_frame_unlabeled 
%  mst_frame 
%  path_frame_distance 
%  mst_path_frame 
%  mst_path 
%  mst_path_length 
%  mst_link 
%  mst_path_directed 
%  mst_path_unlabeled 
\end{description}

\section{Local formulae}
\label{sec:local}

A formula is local if its groundings relate any number of observed ground atoms to exactly one hidden ground atom. For example, a grounding of the local formula 
\[lemma(p,+l_1) \wedge lemma(a,+l_2) \Rightarrow hasRole(p,a)\]
can be seen in the Markov Network of Figure \ref{fig:local2}. It connects a hidden \emph{hasRole} ground atom to two observed \emph{lemma} ground atoms. Note that the ``+'' prefix for variables indicates that there is a different weight for each possible pair of lemmas $(l_1,l_2)$.

\begin{figure}
\begin{center}
    \includegraphics[scale=.70]{LocalFormula2}
\end{center}
\caption{Factor graph for the local formula in section \ref{sec:local}.}
\label{fig:local2}
\end{figure}

For the predicates \emph{isPredicate} and \emph{isArgument} we define the
following formuale:
\begin{description}
    \item[$Word$] a rule for the orthography of possible predicate or argument.
    \item[$Lemma_{-2,-1,1,2}$] for each lemma in a window of two previous and two following token a rule of possible predicate or argument.
    \item[$POSs_{-2,-1,1,2}$] for each POS in a window of two previous and two following tokens a rule of possible predicate or argument.
    \item[$CoarsePOS$] a rule for the previous and the following coarse POS tags of possible predicate or argument.
    \item[$CoarsePOS_2$] a rule for the two previous and two following corar POS tags of possible predicate or argument.
    \item[$DependecyChildren$] a rule for the dependencies of each child of possible predicate or argument.
    \item[$DependecyParent$] a rule for the dependencies of parent of possible predicate or argument.
    \item[$DependecyChildrenPOS$] a rule for the POS tag for each child  of possible predicate or argument.
    \item[$DependecyChildrenParPOS$] a rule for the POS tag of parent and each child  of possible predicate or argument.
    \item[$MFrame$] a rule for the MFrame of possible predicate or argument.
\end{description}

For the predicate \emph{hasRole} we define the following formulae:
\begin{description}
    \item[*$Lemma$] a rule for the lemmas of possible predicate and argument.
    \item[*$POS$] a rule for the POS tags of possible predicate and argument.
    \item[*$LemmaPOS$] a rule for the lemma of possible predicate and POS of possible argument.
    \item[*$POSLemma$] a rule for the POS of possible predicate and lemma of possible argument.
    \item[$SameLemma$] a rule if possible predicate and argument share the same
        lemma.
    \item[*$SamePOS$] a rule if possible predicate and argument share the same
        POS.
    \item[*$CorsePosTags$] a rule for each combination of coarse POS of pair of token after or before the possible predicate and argument.
    \item[$POSArg_{-1,+1}$] for the previous and following POS tags of tokens of a possible argument
        a rule with the POS tag of a possible predicate.
    \item[$BinDistance_{0,1,2,3,4,5,10}$] a rule for the bin distances among possible predicate and argument.
    \item[*$VoiceBinDistance_{0,1,2,3,4,5,10}$] a rule for the bin distances among possible predicate and argument and the voice of the possible predicate.
    \item[$PalmePruned(POS)$] a rule if the possible predicate and argument are
        pruned by palmer heuristic (extra version with POS tag for predicate).
    \item[$Dependency$] for possible predicate and argument a rule for their
        syntactic dependency.
    \item[*$Dependencies(Voice)$] a rule for syntactic dependencies for both possible predicate and
        argument (extra version with voice).
    \item[$PathLength_{0,1,2,3,4,5,10}$] A rule for each bin of the length of the path among the possible predicate and possible
        argument.
    \item[*$DepPath(Voice)$] a rule for the dependency path among the
        possible predicate and possible argument (extra version for voice).
    \item[*$UnlabelledDepPath(Voice,Lemma)$] a rule for the unlabelled dependency path frame among the
        possible predicate and possible argument (extra versions for voice and
        lemma of predicate and argument).
    \item[*$DepPathFrame(Voice,Lemma)$] a rule for the dependency path frame among the
        possible predicate and possible argument (extra versions for voice and
        lemma of predicate).
    \item[*$PairUnlabelledDepPathFrame(Lemma)$] a rule for the unlabelled dependency path frame among the
        possible predicate and possible argument (extra versions for lemma of
        predicate and arguments).
    \item[$SamePath$] a rule for the dependency path among the
        possible predicate and possible argument if both are the same.
    \item[$SamePathFrame$] a rule for the dependency path frame among the
        possible predicate and possible argument if both are the same.
    \item[*$PPattachment$] for the combination of lemma and POS the child of prepositional phrase as possible argument and possible predicate.
\end{description}
The formulae with the star symbol at the start was defined for the \emph{role}
predicate as well. Additionally, for the role we define:
\begin{description}
    \item[$POS$] a rule for both POS tags of possible predicate and the bin
        distance to the argument.
    \item[$POSPOS$] a rule for the POSs of possible predicate and argument.
    \item[*$Dependencies_{0,1,2,3,4,5,10}$] a rule for bin distances and the syntactic dependencies for both possible predicate and
        argument (extra version with voice).
    \item[$POSPOS_{0,1,2,3,4,5,10}$] a rule for the POS and the bin distances among  possible predicate and argument.
    \item[$BinDistance(Lemmma,Voice)_{0,1,2,3,4,5,10}$] a rule for the bin distances among possible predicate and argument with their lemmas and/or voice.
    \item[*$DepPath(Lemma,CorsePos)$] a rule for the dependency path among the
        possible predicate and possible argument with lemma (extra version for coarse POS, and lemma argument).
    \item[$DepPathDistance(Voice,Lemma)_{0,1,2,3,4,5,10}$] a rule for bin distance among the dependency path of the
        possible predicate and possible argument (extra versions for voice and
        lemma of predicate).
    \item[$DepPathFrameDistance(Voice,Lemma)_{0,1,2,3,4,5,10}$] a rule for bin distance among the dependency path frame of the
        possible predicate and possible argument (extra versions for voice and
        lemma of predicate).
\end{description}

Finally, we define the following local formulae for the \emph{sense} predicate:
\begin{description}
    \item[$sense$] a rule for the sense of a possible predicate.
    \item[$lemma$] a rule for the sense of a possible predicate and its lemma.
\end{description}
With this only two local formulae we try to assign the most common sense to a
predicate. Other reasonable formulae would depend on the arguments of the
predicate. But at the local level, we can not include the arguments of the
predicate since they are unknown. However, in the next section addresses this
constraint.

\section{Global formulae}
\label{sec:global}

\emph{Global} formulae relate several hidden ground atoms. We use them for two purposes: to ensure consistency between the decisions of all SRL stages and to capture some of our intuition about the task. We will refer to formulae that serve the first purpose as \emph{structural constraints}. 

For example, a structural constraint is given by the (deterministic) formula
\[role(p,a,r) \Rightarrow hasRole(p,a)\]
which ensures that, whenever the argument $a$ is given a label $r$ with respect to the predicate $p$, this argument must be an argument of $a$ as denoted by \emph{hasRole(p,a)}. Note that this formula by itself models the traditional ``bottom-up'' argument identification and classification pipeline: it is possible to not assign a role $r$ to an predicate-argument pair $(p,a)$ proposed by the identification stage; however, it is impossible to assign a role $r$ to token pairs $(p,a)$ that have not been proposed as potential arguments.

One example of another class of structural constraints is 
\[
hasRole(p,a)\Rightarrow\exists r.role(p,a,r)
\]
which, by itself, models an inverted or ``top-down'' pipeline. In this architecture the argument classification stage can assign roles to tokens that have not been proposed by the argument identification stage. However, it must assign a label to any token pair the previous stage proposes. 
%IV
Figure \ref{fig:global2} illustrates the structural formulae we use in form of a Markov Network.

For the SRL predicates that perform a labelling task (\emph{role} and \emph{sense}) we also need a structural constraint which ensures that not more than one label is assigned. For instance,
\[
(role(p,a,r_1) \wedge r_1 \neq r_2 \Rightarrow \neg role(p,a,r_2)  )
\]
forbids two different semantic roles for a pair of words. 

The global formulae that capture our intuition about the task itself can be further divided into two classes. The first one uses deterministic or \emph{hard} constraints such as
\begin{eqnarray*}
 &role\left(p,a_{1},r\right)\wedge \neg mod\left(r\right)\wedge a_{1}\neq a_{2}  \Rightarrow\\
  & \neg role\left(p,a_{2},r\right)
\end{eqnarray*}
which forbids cases where distinct arguments of a predicate have the same role unless the role describes a modifier.

The second class of global formulae is \emph{soft} or nondeterministic. For instance, the formula:
\begin{eqnarray*}
  & lemma(p,+l) \wedge ppos(a,+p)  \\
  & \wedge hasRole(p,a)  \Rightarrow sense(p,+f) 
\end{eqnarray*}
is a soft global formula. It captures the observation that the sense of a verb or noun depends on the type of its arguments. Here the type of an argument token is represented by its POS tag.

Table \ref{tbl:global} summarises the formulae we use in this work:

\begin{table}
    7\centering
    \begin{tabular}{|c|}\hline
        Structural Bottom-up\\\hline\hline
        $sense(p,s) \Rightarrow predicate(p)$\\
        $hasRole(p,a) \Rightarrow predicate(p)$\\
        $hasRole(p,a) \Rightarrow argument(a)$\\
        $role(p,a,r) \Rightarrow hasLabel(p,a)$\\
        Structural Top-Down\\\hline\hline
        $isPredicate(p) \Rightarrow\exists s.sense(p,s)$\\
        $isPredicate(p) \Rightarrow\exists a.hasRole(p,a)$\\
        $isArgument(a)  \Rightarrow\exists p.hasRole(p,a)$\\
        $hasLabel(p,a) \Rightarrow\exists r. role(p,a,r)$\\
        Additional Structural\\\hline\hline
        $(role(p,a,r_1) \wedge r_1 \neq r_2 \Rightarrow \neg role(p,a,r_2) )$\\
        $(sense(p,s_1) \wedge s_1 \neq s_2 \Rightarrow \neg sense(p,r_2) )$\\
        Hard constrains\\\hline\hline
        $role\left(p,a_{1},r\right)\wedge \neg mod\left(r\right)\wedge a_{1}\neq a_{2}  \Rightarrow \neg role\left(p,a_{2},r\right) $
        Soft constrains\\\hline\hline
        $ lemma(p,+l) \wedge ppos(a,+p) \wedge hasRole(p,a)  \Rightarrow sense(p,+f) $ \\
        $ lemma(p,+l) \wedge role(p,a,+r) \Rightarrow sense(p,+f) $ \\
        \hline
    \end{tabular}
    \caption{Global formulae for ML model}
    \label{tbl:global}
\end{table}

\begin{figure}
\begin{center}
   \includegraphics[scale=.70]{GlobalFormula2}
\end{center}
\caption{Markov Network that illustrates the structural constraints we use.}
\label{fig:global2}
\end{figure}






% Finally, to our last group of rules belongs the soft formulae and hard constrains with extra linguistic knowledge. Figure \ref{fig:global2} shows an example of soft formulae. An example, of hard constriain which uses extra linguistic knowledge is:
% \begin{eqnarray*}
%  & role\left(p,a_{1},r\right)\wedge arg\left(r\right)\wedge a_{1}\neq a_{2} & \Rightarrow\\
%   & \neg role\left(p,a_{2},r\right)
% \end{eqnarray*}
% In this case we constrain to one semantic role to the words identify as proper arguments by the Palmer's heuristics. % ??
%
%We have slit our global formulae into four groups. The first, are hard constrains which only involve one hidden predicate. The second one correspond to the hard constrains which involve more than one hidden predicate but follow a bottom-up strategy. This is conect two hidden predicates following the pipeline of the stages of the task. The top-down group group goes in a different direction. And finally, the fourth group contains the global formulae. In the section \ref{sec:results} we will explore how these relations contribute to the whole model. Table \ref{tbl:global} enumerate the global formulae used in this work.
%\begin{table}
%\begin{tabular}{|l|p{6cm}|}\hline
%Group & Description \\\hline
%1st   & There is one or less $role$ predicates for a pair of words (see Figure \ref{fig:hard1}.)\\
%      & There is one or less $frameLabel$ predicates for a word\\
%      & There are more than one $haslabel$ predicate for each word which is a possible argument by the Palmer heuristics\\\hline
%2nd   & If there is a $isPredicate(p)$ predicate, there must be a $frameLabel(p,_)$ predicate\\
%      & If thrre is a $isPredicate(p)$ predicate, there must be a $hasLabel(p,_)$ predicate\\      
%      & If there is a $hasLabel(p,a,_)$ predicate, there must be a $role(p,a,_)$ predicate\\\hline
%3rd   & If there is a $role(p,a,_)$ predicate, there must be a $hasLabel(p,a)$ predicate. \\
%      & If there is a $frameLabel(p,_)$ predicate, there must be a $isPredicate(p)$ predicate\\
%      & If there is a $hasLabel(p,_)$ predicate, there must be a $isPredicate(p)$ predicate.\\
%      & If there is a $hasLabel(_,a)$ predicate, there must be a $isArgument(a)$ predicate.\\\hline
%4th   & There shouldn't be two $hasLabel$ predicate for the which have as a predicate the same word, and the two arguments are prepositional phrases.\\
%      & There shouldn't be two predicates which overlap\\
%      & A $frameLabel$ predicated depends of the POS tags of the arguments of the predicate (see Figure \ref{fig:global1}\\
%      & For each proper argument defined by the Palmer heuristics there should be at most one $role$ predicate for that argument\\\hline
%      \end{tabular}
%\caption{Global formulae }
%\label{tbl:global}
%\end{table}
%


