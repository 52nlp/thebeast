For our experiments we use the corpora provided in the SRL only shared task. We 
test the ML model with the following languages: Catalan and Spanish 
\citep{catalan-and-spanish-data} , Chinese \citep{chinese-data}, Czech 
\citep{czech-data}\footnote{For training we use only sentences shorter than 40 
words in this corpus.}, English \citep{english-data}, German 
\citep{german-data}, Japanese \citep{japanese-data}. 

Table \ref{tbl:results} presents the f1-scores and times for the development and
in-domain corpora. The model better captures the SRL task for the English 
language. This is in part because the original model was originally developed 
using for English. The model has the poorer performance for the German language.  
In section \ref{sec:analysis} we review the typical errors of our system. In 
general, our SRL system is the third best of the systems in the \emph{SRLOnly} 
track of the Shared Task, and it is the sixth for system on both \emph{Joint} 
and \emph{SRLOnly} tracks. For five of the languages the difference of F1 scores 
between our system and best score on the language is of $3\%$.  However, for 
German is of  $6.19\%$ and for Czech $10.76\%$.  Reviewing, the precision and 
recall of the semantic labelling we found that our system has a higher precision 
than recall (we have the fifth best average precision and the eighth average 
recall).

In terms of time performance, we found the Chinese corpus the slower system to 
train. We are not sure of the cause of this timing. In the case of testing, our 
slowest set was Czech which corresponds to the longest testing set. 

\begin{table}
\begin{center}
\small
\begin{tabular}{|l|l|l|c|c|}\hline
Language           & Devel        & Test       & Train time  & Test time  
\\\hline\hline
%role score a
% average len dev, average len train, num preds
Catalan         & $78.10\%$    & $78.00\%$  & 6h 11m  & 14m   \\ %0.740
%53060/1862=28.5, 390302 13200 29.5683, 37508,
Chinese         & $77.97\%$    & $77.73\%$  & 36h 30m & 34m   \\ %0.700
%73153/2556=28.6, 609060 22277 27.3403, 102832,
Czech           & $75.98\%$    & $75.75\%$  & 14h 21m & 1h 7m \\ %0.733
%70348/4213=16.7, 652544 38727 16.8498, 421281,
English         & $82.28\%$    & $83.34\%$  & 12h 26m & 16m   \\ %0.770
%57676/2399=24.0, 958167 39279 24.3939, 192766,
German          & $72.05\%$    & $73.52\%$  & 2h 28m  & 7m    \\ %0.712
%31622/2000=15.8, 648677 36020 18.0088, 18661,
Japanese        & $76.34\%$    & $76.00\%$  & 2h 17m  & 4m    \\ %0.609
%13615/500=27.2, 112555 4393 25.6214, 26605,
Spanish         & $78.03\%$    & $77.91\%$  & 6h 9m   & 16m   \\ %0.744
%50630/1725=29.4, 427442 14329 29.8306, 44371,

\hline
\end{tabular}
\caption{F-scores for in-domain in corpora for each language.}
\label{tbl:results}
\normalsize
\end{center}
\end{table}

Table \ref{tbl:outresults} presents the F1 scores of our system for the out of 
domain test corpora. We observe a similar tendency, our system is the sixth best 
for both \emph{Joint} and \emph{SRLOnly} tracks. Besides we observe a similar 
large differences between our system and the best score for German and Czech 
(i.e., $>7.5\%$), while for English this is relativily small (i.e., $<3\%$). 

\begin{table}
\begin{center}
\small
\begin{tabular}{|l|c|}\hline
Language        & Test       \\\hline\hline
Czech           & $77.34\%$  \\
English         & $71.86\%$  \\
German          & $62.37\%$  \\
\hline
\end{tabular}
\caption{F-scores for out-domain in corpora for each language.}
\label{tbl:outresults}
\normalsize
\end{center}
\end{table}

Additionally, we test the effect of the \emph{argument siblings} set of formulae 
introduced for the Japanese ML model. Table \ref{tbl:japanese} show the results 
for this setting for the test set of Japanese. We observe that the performance is 
worst by more that $6\%$.

\begin{table}
\begin{center}
\small
\begin{tabular}{|l|l|l|}\hline
Language           & Test      \\\hline\hline
Japanese           & $69.52$     \\ %0.609
\hline
\end{tabular}
\caption{F-scores for the Japanese test set without \emph{argument siblings} set 
of formulae.}
\label{tbl:japanese}
\normalsize
\end{center}
\end{table}


%% Note german high exact match, most of the examples in the development set
%% do not have a predicate to label.

%\begin{table}
%\begin{center}
%\small
%\begin{tabular}{|l|c|c|}\hline
%Language        & Proposition         & Exact match \\
                %&              &            \\\hline\hline
%Catalan         & $46.69\%$ & $22.02\%$  \\
%Chinese         & $44.00\%$ & $20.70\%$  \\
%Czech           & $68.01\%$ & $8.64\%$  \\
%English         & $50.24\%$ & $19.55\%$  \\
%German          & $44.00\%$ & $85.20\%$  \\
%Japanese        & $35.36\%$ & $5.80\%$  \\
%Spanish         & $47.27\%$ & $20.75\%$  \\
%\hline
%\end{tabular}
%\caption{Proposition and exact semantic match scores for out-of-domain corpora.}
%\label{tbl:results}
%\normalsize
%\end{center}
%\end{table}



