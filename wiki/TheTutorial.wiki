#summary One-sentence summary of this page.

= Introduction =

This is a thebeast tutorial. We use a semantic tagger as example application.

= Installation =

== Download ==

Go to "Source" and use svn for now

== compile ==

cd into the thebeast directory and call

{{{
ant -f thebeast.xml
}}}

to compile the source. 

TheBeast can be started by calling 

{{{
bin/linux/thebeast 
}}}

on linux machines and

{{{
bin/mac/thebeast 
}}}

on the mac.

= Defining a model =

== Types ==
{{{
type Slot: From_loc, "to_loc";
type Word: ... "a", "man";
}}}
== Predicates ==
{{{
predicate slot: Int x Slot;
predicate word: Int x Word;
}}}

== Defining the Model ==
{{{
hidden: slot;
observed: word;
}}}

== Local Features ==


== Load corpus ==

{{{
load corpus from "corpus1.txt";
}}}

== check data ==

So far we have loaded the corpus, but not into RAM. It will be streamed from files in a sequential manner when we learn or test our model. To inspect the corpus it needs to be loaded into ram by 
{{{
save corpus to ram;
}}} 

Now you can move around the corpus using 
{{{
next;
}}}
and 
{{{
prev
}}}
and 
{{{
print atoms.words;
}}}
to print all words of the current sentence/database.

= Learning =
{{{
print atoms.slot;
}}}

== Collect Features ==

{{{
collect;
}}}

== Learn ==

{{{
save corpus to instances "/tmp/instances.dmp";
}}}
{{{
set learner.update = "mira";
set learner.loss = "avgF1";
set learner.loss = "globalNumErrors";
}}}

{{{
learn for 10 epochs;
}}}

{{{
save weights to dump "/tmp/weights.dmp";
}}}

= Testing =
{{{
load weights from dump "/tmp/weights.dmp";
load corpus from "/tmp/testcorpus.txt";
test to "/tmp/output.txt";
}}}

== Inspecting the results ==

= Extending the model =






Add your content here.  Format your content with:
  * Text in *bold* or _italic_
  * Headings, paragraphs, and lists
  * Automatic links to other wiki pages