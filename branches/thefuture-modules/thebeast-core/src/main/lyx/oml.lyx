#LyX 1.6.4.1 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass article
\use_default_options true
\language english
\inputencoding auto
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Title
Extendable Markov Logic (ExML)
\end_layout

\begin_layout Abstract
Markov Logic has been very succesful
\end_layout

\begin_layout Abstract
At the same time, it remains in flux: new language concepts are constantly
 introduced (blocking, weight constraints, cardinality).
 Many of them are actually not increasing the actual expressivity but make
 inference easier.
 
\end_layout

\begin_layout Abstract
This suggests a language/framework that accomodates for new extensions or
 subsets to the language while re-using a maximal amount of existing infrastruct
ure.
 
\end_layout

\begin_layout Abstract
We therefore propose 
\noun on
Extendable Markov Logic
\noun default
, a language that centers around variables, possible worlds and the notion
 of scoring or prob functions over possible worlds.
 In Ex Markov Logic the developer gets to compose these prob functions.
 The core ML building blocks are quantifications, boolean connectives and
 indicator functions that map boolean values to real values.
 These allow to reproduce Markov Logic in a very intuitive fashion.
 
\end_layout

\begin_layout Abstract
However, the core feature of ExML is that it allows us to readily define
 new building blocks of scoring functions.
 This can be used to directly implement blocking etc.
 It can also be used to introduce novel blocks, such as cardinality constraints,
 or acyclicity constraints.
 
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Markov Logic has been successfully applied for various tasks, and is currently
 gaining momentum as one of the leading probababilistic programming languages.
 This is probably due to various reasons: its expressivity, its simplicity,
 the active development of an interpreter, etc.
 However, when looking at the history of Markov Logic, as well as its main
 software manifestiation, alchemy, another reason becomes apparent.
 Markov Logic is actually a somewhat fluent, evolving language that has
 been accomodating new constructs as see fit.
 For example, the plus-notation, blocking syntax, hybrid markov logic, etc.
 
\end_layout

\begin_layout Standard
We argue that this flexibility, or evolution, is essential for the further
 progress of Markov Logic as interface language between applications and
 AI technology.
 In particular, we think that Markov Logic will need to accomodate more
 types of constraints and expressions than predicates, conjunctions and
 quantifications.
 This is best exemplified in the need of tree constraint expressions.
 While it is possible to use FOL to define a certain predicate to be a tree,
 it generally leads to hard inference problems.
 However, there exists a multitude of methods for inference with tree constraint
s.
 By default ML, as interface to AI technology, discards all this methods
 and sees everything as clauses.
 Another example are CPTs: while a MLN can represent each finite distribution,
 it discards the structure both for learning and testing.
 
\end_layout

\begin_layout Standard
In this work we therefore present a framework that will allow Markov Logic
 to grow in the above presented ways: 
\noun on
Extendable Markov Logic
\noun default
 (ExML).
 This is done by extracting what we think are the essential aspects of Markov
 Logic: the declarative construction/assembly of scoring functions for possible
 worlds based on quantified formulae and real valued terms over structured
 first order variables.
 We provide default building blocks for this assembly, but more importantly,
 we provide interfaces and inference frameworks that allow users to add
 new types of building blocks, such as a tree constraint.
 
\end_layout

\begin_layout Standard
ExML is also closely related to factorie: here users can define factor graphs
 (our scoring functions in our lingo) and inference/learning in these graphs
 imperatively.
 This enables them to realize something like a tree constraint by allowing
 the user to plug in jump functions that preserve treeness.
 In a way, ExML can be seen as the declarative pedant to factorie: scoring
 functions are still declaratively composed, but the user can introduce
 new building blocks in this construction.
 
\end_layout

\begin_layout Standard
Roughly speaking, ExML allows you to write
\end_layout

\begin_layout LyX-Code

\size footnotesize
sum {(i,j) => $(pos(i,
\begin_inset Quotes erd
\end_inset

NN
\begin_inset Quotes erd
\end_inset

) & pos(j,
\begin_inset Quotes erd
\end_inset

DT
\begin_inset Quotes erd
\end_inset

) ==> link(i,j)) * 2.5} + tree(link)
\end_layout

\begin_layout Standard
the first summand is essentially the log linear score of a Markov Logic
 formula (note that $ is our shortform for the indicator function mapping
 bools to doubles).
 The second a new building block we defined in our framework.
 It evaluates to 0 if the predicate link is a tree in a given possible world,
 and 
\begin_inset Formula $-\infty$
\end_inset

 otherwise.
 Note that this scoring function is equivalent to 
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\sum_{i,j}\left[pos\left(i,NN\right)\wedge pos\left(j,DT\right)\Rightarrow link\left(i,j\right)\right]\cdot2.5+tree\left(link\right)\]

\end_inset


\end_layout

\begin_layout Standard
Here 
\begin_inset Formula $\left[\cdot\right]$
\end_inset

 is the Iverson bracket[cite].
\end_layout

\begin_layout Standard
The first embodiement of ExML is implemented in Scala.
 This allows us to avoid designing and own syntax for our language---all
 expressions are realized through operator overloading and other techiques
 within Scala.
 It also allows tight integration and the possibility to generate templates.
 It also makes the definition of new building blocks hassle-free.
\end_layout

\begin_layout Standard
Note that ExML also allows variables to be a) propositional, b) functions
 (over functions) and c) categorical values.
 Again, while we can use ML to simulate such variables, our framework is
 cleaner, leads to better inference (or easier to find tractable substructure).
 
\end_layout

\begin_layout Itemize
relation to factorie
\end_layout

\begin_layout Section
Some Theory
\end_layout

\begin_layout Itemize
Treat every formula as a term 
\end_layout

\begin_layout Itemize
Functional Type Theory (Church, inspired by Frege) used here
\end_layout

\begin_layout Itemize
MLNs etc: Relational Type Theory
\end_layout

\begin_layout Itemize
Compared to Blog, Church etc: here terms are deterministic, there terms
 are random variables
\end_layout

\begin_layout Itemize
The strength of the lambda-calculus is that it is easily used as a "glue"
 on top of a richer world of primitives.
 Its advantages as a glue are that it has a natural correspondence with
 the way that people program, and natural compilation techniques yield high-perf
ormance code.
 The latter comes through optimizations know as tail-call and continuation-passi
ng, which might be the subject of future talks.
\end_layout

\begin_layout Itemize
The Environment Model of Evaluation (functional)
\end_layout

\begin_layout Itemize
Title: Functional Programming of Scores over Possible Worlds
\end_layout

\begin_deeper
\begin_layout Itemize
vs Function Programming of Random Variables
\end_layout

\end_deeper
\begin_layout Itemize
Formulas are terms.
 Some (http://mally.stanford.edu/Papers/rtt.pdf) argue: In this paper we develop
 an argument that suggests Whitehead & Russell’s approach to the foundations
 of logic, which takes relations as basic, is to be preferred to Frege’s
 and Church’s.(difference between RTTs and FTTs with regard to their ability
 to represent systems containing formulas that aren’t, and can’t be converted
 to, terms.)
\end_layout

\begin_layout Itemize
http://en.wikipedia.org/wiki/Principle_of_compositionality
\end_layout

\begin_layout Itemize
http://en.wikipedia.org/wiki/Value-level_programming
\end_layout

\begin_layout Itemize
http://plato.stanford.edu/entries/type-theory-church/
\end_layout

\begin_layout Itemize
Henkin's (1950) standard model for semantics
\end_layout

\begin_layout Itemize
look at model theory for church type theory and use a bit of their terminology
\end_layout

\begin_layout Itemize
http://imps.mcmaster.ca/doc/seven-virtues.ps
\end_layout

\begin_layout Itemize
valuation function
\end_layout

\begin_layout Itemize
Quantification=Definite Description
\end_layout

\begin_layout Section
Variables and Possible Worlds
\end_layout

\begin_layout Standard
In Markov Logic we define probability distributions over possible worlds.
 In the widest sense, a possible world is a mapping from variables to the
 set of values these variables take on.
 In the propositional case, consider a boolean variable 
\begin_inset Formula $x$
\end_inset

, then a possible world is 
\begin_inset Formula $x\rightarrow true$
\end_inset

.
 In the first order case, consider a variable 
\begin_inset Formula $p\in Person\times Person\Rightarrow\mathbb{B}$
\end_inset

.
 Here 
\begin_inset Formula $p$
\end_inset

 is a variable that is mapped to a relation, and a possible world is 
\begin_inset Formula $p\rightarrow\left\{ \left(Anna,Person\right),\ldots\right\} $
\end_inset

.
 
\end_layout

\begin_layout Standard
The first thing we do in ML, and ExML, is to define our basic atomic domains:
 the set of values that our variables can take on.
\end_layout

\begin_layout LyX-Code
val Persons = Domain(
\begin_inset Quotes eld
\end_inset

Anna
\begin_inset Quotes erd
\end_inset

, ...)
\end_layout

\begin_layout LyX-Code
val Ages = Ints(0 until 100)
\end_layout

\begin_layout LyX-Code
val Heights = Doubles(0,230.0)
\end_layout

\begin_layout LyX-Code
...
\end_layout

\begin_layout Standard
Now we define variables.
 In Markov Logic this means predicates, here it can mean anything from propositi
onal variables to complex functional variables:
\end_layout

\begin_layout LyX-Code
val smokes = Var(Persons -> Bools)
\end_layout

\begin_layout LyX-Code
val friends = Var(Persons x Persons -> Bools)
\end_layout

\begin_layout LyX-Code
val height = Var(Person -> Heights)
\end_layout

\begin_layout LyX-Code
...
\end_layout

\begin_layout Standard
A possible world is a assignment from variables to values.
 The common mode of operation is to partially define possible worlds (the
 observations) and infer the rest (or infer marginal probabilities).
 
\end_layout

\begin_layout LyX-Code
val world = new MutableWorld
\end_layout

\begin_layout LyX-Code
world(smokes) = ClosedFunction(Anna->True) //or
\end_layout

\begin_layout LyX-Code
world(smokes(Anna)) = true
\end_layout

\begin_layout LyX-Code

\end_layout

\begin_layout Standard
Variables can also be functions, and hence predicates:
\end_layout

\begin_layout LyX-Code
val age = 
\begin_inset Quotes eld
\end_inset

age
\begin_inset Quotes erd
\end_inset

 <- Ints(0,120) x Persons -> Bools
\end_layout

\begin_layout Standard
again, a possible world is a mapping from variables to their values.
 In this case
\end_layout

\begin_layout LyX-Code
world(age) = Function((12,
\begin_inset Quotes erd
\end_inset

Anna
\begin_inset Quotes erd
\end_inset

)->true, ...) //or
\end_layout

\begin_layout LyX-Code
world(age(12,
\begin_inset Quotes erd
\end_inset

Anna
\begin_inset Quotes erd
\end_inset

)) = true
\end_layout

\begin_layout Standard
note that functions can also be point to functions.
 
\end_layout

\begin_layout Subsection
Composite Variables
\end_layout

\begin_layout Standard
predicates vs ground atoms
\end_layout

\begin_layout Section
Terms and Scoring Functions
\end_layout

\begin_layout Standard
A Markov Logic Network is a probability or score function defined over possible
 worlds.
 In ExML we follow the same path.
 However, we break the scoring function into building blocks.
 These blocks essentially correspond to the terms we find in the actual
 definition of MLNs, and actually the definitions of scoring functions in
 research papers.
 
\end_layout

\begin_layout Subsection
Terms
\end_layout

\begin_layout Standard
The main unit of these scoring function are terms.
 A term is simply a symbolic value that can be evaluated to a an actual
 value given a possible world.
 For example, a variable is a term.
\end_layout

\begin_layout LyX-Code
smokes
\end_layout

\begin_layout Standard
For a given possible world, this term can be resolved to be, say, 
\begin_inset Formula $\left\{ Anna\rightarrow True\right\} $
\end_inset

, by replacing 
\emph on
smokes
\emph default
 with its value in the possible world.
 The same holds for 
\end_layout

\begin_layout LyX-Code
smokes(Anna)
\end_layout

\begin_layout Standard
Here the term is recursively resolved in the natural way: the constant Anna
 is resolved to the value Anna, the variable smokes to a function from person
 values to booleans, and the function application to the value of the smokes
 function applied to the value Anna.
 For example, this term could evaluate to 
\emph on
True
\emph default
.
 
\end_layout

\begin_layout Standard
How can this be used to define a scoring function? We define scoring functions
 simply as
\emph on
 real valued terms
\emph default
.
 So together with a
\emph on
 Indicator operator
\emph default
 $ that maps booleans to 1.0 or 0.0, this is a scoring function
\end_layout

\begin_layout LyX-Code
$(smokes(Anna))
\end_layout

\begin_layout Standard
which assigns the value 1.0 to worlds where Anna smokes, and 0.0 otherwise.
 Another example is 
\end_layout

\begin_layout LyX-Code
$(smokes(Anna)) + height(Anna)
\end_layout

\begin_layout Standard
Giving the score 181 to the world 
\begin_inset Formula $smokes\rightarrow\left\{ Anna\rightarrow true\right\} ,height\rightarrow\left\{ Anna\rightarrow180\right\} $
\end_inset

.
 Meaning: a world gets more likely with Anna smoking and being tall.
 
\end_layout

\begin_layout Standard
More formally, a term is an instance of an abstract datatype:
\end_layout

\begin_layout Itemize

\emph on
eval
\emph default
 function: maps world to value
\end_layout

\begin_layout Itemize

\emph on
variables
\emph default
 function: returns all atomic free variables inside the term
\end_layout

\begin_layout Subsection
Quantification
\end_layout

\begin_layout Standard
The above presents terms and double/real terms as the building blocks that
 make up scoring functions.
 However, so far we can only talk about specific problem instances.
 We would need to define a new smoking model for each set of persons we
 encounter.
 This is where quantification comes in to play.
 In ExML we can compose scoring functions that apply a certain to ###.
 For example, the scoring function
\end_layout

\begin_layout LyX-Code
$(forall(Persons){x=>smokes(x)})
\end_layout

\begin_layout Standard
assigns 1.0 to a world where everyone smokes and 0 otherwise.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Note that the forall we have here as the usual FOL semantics.
\end_layout

\end_inset

 However, this is not what we want to do.
 Instead we want to assign a higher score to worlds with more people smoking.
\end_layout

\begin_layout LyX-Code
sum(Persons) {x=>$(smokes(x)) * 1.5}
\end_layout

\begin_layout Standard
The scoring function that this term defines explains itself: we create one
 ...
\end_layout

\begin_layout LyX-Code
sum(Persons,Persons) {(x,y)=>$(friends(x,y) ==> (smokes(x)<==>smokes(y))
 * 0.142}
\end_layout

\begin_layout Standard
asd
\end_layout

\begin_layout LyX-Code
forall(Values) = quantified(And,Values)
\end_layout

\begin_layout LyX-Code
exists(Values) = quantified(Or,Values)
\end_layout

\begin_layout LyX-Code
sum(Values) = quantified(Sum,Values)
\end_layout

\begin_layout Standard
and so forth.
 
\end_layout

\begin_layout Standard
In fact we are now ready to specify MLNs, and their propositional counter-parts.
 However, we can already do much more:
\end_layout

\begin_layout LyX-Code
sum(Persons,Ints) {p,a => $(age(p,a)) * $(a) * 2.0}
\end_layout

\begin_layout Subsection
Vectors
\end_layout

\begin_layout Standard
Many probabilistic models are represented as 
\begin_inset Formula \[
exp\left(f\left(\mathbf{x},\mathbf{y}\right)^{\top}\mathbf{w}\right)\]

\end_inset


\end_layout

\begin_layout Standard
Here the moments, parameters of the probabilistic model are clearly separated
 fromt he structural part.
 However, in our current scoring function this is not the case.
 we could write
\end_layout

\begin_layout LyX-Code
vectorsum(Persons,Ints) {p,a => $(age(p,a)) * $(a) * 1_(
\begin_inset Quotes eld
\end_inset

age
\begin_inset Quotes erd
\end_inset

,p)}
\end_layout

\begin_layout Standard
here 1_(p) is the unit vector active at component p.
 Now we have a representation of the feature function.
 
\end_layout

\begin_layout LyX-Code
sum(Persons,Ints) {p,a => $(age(p,a)) * $(a) * w_age(p)}
\end_layout

\begin_layout Standard
but this requires a new variable (w_age) for each formula.
 
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\nexists\ \]

\end_inset


\end_layout

\begin_layout Subsection
Alchemy Style Markov Logic
\end_layout

\begin_layout LyX-Code
$(a(x) & b(x)) * 2.0
\end_layout

\begin_layout LyX-Code
$(a(x)) * 1.0 + $(b(x)) * 1.0
\end_layout

\begin_layout LyX-Code
$$(a(x) & b(x)) * 2.0
\end_layout

\begin_layout LyX-Code
$$(a(x) & b(x)) * 1_(x)
\end_layout

\begin_layout LyX-Code
AlchemyTerm(BooleanTerm) extends Sum(...)
\end_layout

\begin_layout LyX-Code
Individisble(BooleanTerm) extends BooleanTerm
\end_layout

\begin_layout Section
Extending Extentable Markov Logic
\end_layout

\begin_layout Subsection
Trees
\end_layout

\begin_layout LyX-Code
tree(link,word)
\end_layout

\begin_layout Itemize
Network flow representation in ILP
\end_layout

\begin_layout Itemize
Separation algorithm
\end_layout

\begin_layout Itemize
Matrix Tree theorem
\end_layout

\begin_layout Subsection
Similarity Logic
\end_layout

\begin_layout Subsection
Cardinality Constraints
\end_layout

\begin_layout Section
Inference and Learning
\end_layout

\begin_layout Subsection
Trees
\end_layout

\begin_layout LyX-Code
val submodel = x + y + z ...
\end_layout

\begin_layout LyX-Code
submodel.inferMarginalsWith()
\end_layout

\begin_layout Subsection
Hooks
\end_layout

\begin_layout Subsection
Generalized MWS
\end_layout

\begin_layout Subsection
Gradient Based & Online Learning
\end_layout

\begin_layout Section
Examples
\end_layout

\end_body
\end_document
